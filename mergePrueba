; ************************************************************************* ;
; Organizacion del Computador II                                            ;
;                                                                           ;
;   Implementacion de la funcion Merge 1                                    ;
;                                                                           ;
; ************************************************************************* ;

; void ASM_merge1(uint32_t w, uint32_t h, uint8_t* data1, uint8_t* data2, float value)
global ASM_merge1


;value--> xmm0



section .data
uno: dd 0.1, 0.0, 0.0, 0.0


section .text


ASM_merge1:


xorps xmm5, xmm5

;mov rcx, w*h cantidad de pixeles

;mov eax, esi
;mov ecx, edi
;imul rcx, rax

;xor r8, r8
;mov r8, 1

mov r12, 65536
;cvtsi2ss xmm2, r8

movdqu xmm2, [uno]



xorps xmm1, xmm1        ; xmm1 = 0 | 0 | 0 | 0
addss xmm1, xmm2        ; xmm1 = 0 | 0 | 0 | 1
pslldq xmm1, 4          ; xmm1 = 0 | 0 | 1 | 0
addss xmm1, xmm0        ; xmm1 = 0 | 0 | 1 | value
pslldq xmm1, 4          ; xmm1 = 0 | 1 | value | 0
addss xmm1, xmm0        ; xmm1 = 0 | 1 | value | value
pslldq xmm1, 4          ; xmm1 = 1 | value | value | 0
addss xmm1, xmm0        ; xmm1 = 1 | value | value | value




.ciclo:

	movdqu xmm3, [rdx]
	movdqu xmm4, xmm3
	punpcklbw xmm4, xmm5  ; extendemos a 16 bits los 8 numeros de la parte baja.
	movdqu xmm6, xmm4     ; los 8 numeros de la parte baja en 32 bit
	punpcklwd xmm4,xmm5   ; extendemos a 32 bits los 4 numeros de la parte baja-baja.
	punpckhwd xmm6,xmm5   ; extendemos a 32 bits los 4 numeros de la parte baja-alta.


	movdqu xmm7, xmm3
	punpckhbw xmm7, xmm5  ; extendemos a 16 bits los 8 numeros de la parte alta.
	movdqu xmm8, xmm7     ; los 8 numeros de la parte alta en 32 bit
	punpcklwd xmm7,xmm5   ; extendemos a 32 bits los 4 numeros de la parte alta-baja.
	punpckhwd xmm8,xmm5   ; extendemos a 32 bits los 4 numeros de la parte alta-alta.
	
	
	cvtdq2ps xmm4,xmm4    ; convertimos a float		
	mulps xmm4,xmm1       ; multiplicamos por value
	cvtps2dq xmm4, xmm4   ; lo volvemos a convertir en enteros de 32
	packssdw xmm4,xmm4    ; xmm4 = primeros 4 resultados
	packuswb xmm4,xmm4    ; los devolvemos a byte
	

	cvtdq2ps xmm6,xmm6    ; convertimos a float		
	mulps xmm6,xmm1       ; multiplicamos por value
	cvtps2dq xmm6, xmm6   ; lo volvemos a convertir en enteros de 32
	packssdw xmm6,xmm6    ; xmm4 = primeros 4 resultados
	packuswb xmm6,xmm6    ; los devolvemos a byte

	cvtdq2ps xmm7,xmm7    ; convertimos a float		
	mulps xmm7,xmm1       ; multiplicamos por value
	cvtps2dq xmm7, xmm7   ; lo volvemos a convertir en enteros de 32
	packssdw xmm7,xmm7    ; xmm4 = primeros 4 resultados
	packuswb xmm7,xmm7    ; los devolvemos a byte



	cvtdq2ps xmm8,xmm8    ; convertimos a float		
	mulps xmm8,xmm1       ; multiplicamos por value
	cvtps2dq xmm8, xmm8   ; lo volvemos a convertir en enteros de 32
	packssdw xmm8,xmm8    ; xmm4 = primeros 4 resultados
	packuswb xmm8,xmm8    ; los devolvemos a byte
	

	xorps xmm9, xmm9        ; xmm9 = 0 | 0 | 0 | 0
	paddb xmm9, xmm4        ; xmm9 = 0 | 0 | 0 | baja-baja
	pslldq xmm9, 4          ; xmm9 = 0 | 0 | baja-baja | 0
	paddb xmm9, xmm6        ; xmm9 = 0 | 0 | baja-baja | baja-alta
	pslldq xmm9, 4          ; xmm9 = 0 | baja-baja | baja-alta | 0
	paddb xmm9, xmm7        ; xmm9 = 0 | baja-baja | baja-alta | alta-baja
	pslldq xmm9, 4          ; xmm9 = baja-baja | baja-alta | alta-baja | 0
	paddb xmm9, xmm8        ; xmm9 = baja-baja | baja-alta | alta-baja | alta-alta



	movdqu [rdx], xmm9
	add rdx, 16
	
	
	
	
	dec r12
	cmp r12, 0
	jne .ciclo
	
	

 ret


